{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding entity classes in embeddings\n",
    "\n",
    "In this notebook we're going to use embeddings to find entity classes and how they correlate with other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from keras.utils import get_file\n",
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(12, 8)\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL    = 'GoogleNews-vectors-negative300.bin'\n",
    "data_loc = '/home/smithw/Downloads/deep_learning' # WS: files not backed up here\n",
    "zipped   = os.path.join(data_loc, MODEL + '.gz')  # WS mod\n",
    "unzipped = os.path.join(data_loc, MODEL)  # WS\n",
    "zipped, unzipped"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "path = get_file(MODEL + '.gz', 'https://s3.amazonaws.com/dl4j-distribution/%s.gz' % MODEL)\n",
    "unzipped = os.path.join('generated', MODEL)\n",
    "if not os.path.isfile(unzipped):\n",
    "    with open(unzipped, 'wb') as fout:\n",
    "        zcat = subprocess.Popen(['zcat'],\n",
    "                          stdin=open(path),\n",
    "                          stdout=fout\n",
    "                         )\n",
    "        zcat.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(unzipped, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model), type(model.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Germany'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Annita_Kirsten'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = list(csv.DictReader(open('data/countries.csv')))\n",
    "len(countries), countries[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.key_to_index), len(model.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN SVM ON COUNTRY NAMES vs NON-COUNTRY NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(countries), len(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# examples of country names for training\n",
    "num_countries = 140\n",
    "positive = [x['name'] for x in random.sample(countries, num_countries)]\n",
    "positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exampls of not-country names\n",
    "sample = 10000 # WS note: this may randomly contain some countries, but unlikely out of 3e6 tokens\n",
    "negative = random.sample(model.index_to_key, sample)  # WS this works\n",
    "negative[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now label the data\n",
    "labelled = [(p, 1) for p in positive] + [(n, 0) for n in negative]\n",
    "random.shuffle(labelled)\n",
    "X = np.asarray([model[w] for w, l in labelled])\n",
    "y = np.asarray([l        for w, l in labelled])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labelled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y) == num_countries  # add up all the truth: should be same as num_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FRACTION = 0.1\n",
    "cut_off = int(TRAINING_FRACTION * len(labelled))\n",
    "clf     = svm.SVC(kernel='linear')  # support-vector classification\n",
    "clf.fit(X[:cut_off], y[:cut_off])  # training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svm.SVC?, svm.SVC.fit?\n",
    "#svm.SVC.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions from the validation set\n",
    "res = clf.predict(X[cut_off:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on validation data\n",
    "missed = [(country, pred) for (pred, truth, country) in zip(res, y[cut_off:], labelled[cut_off:]) if pred != truth]  # WS mod\n",
    "100 - 100 * float(len(missed)) / len(res), missed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# WS create a truth table for more detailed analysis\n",
    "total = res.shape[0]\n",
    "tab = {(1, 1): 'TRUE  POSITIVE', (0, 0): 'TRUE  NEGATIVE', (1, 0): 'FALSE NEGATIVE', (0, 1): 'FALSE POSITIVE'}\n",
    "score = {(1, 1): 0, (0, 0): 0, (1, 0): 0, (0, 1): 0}\n",
    "for t, p in zip(y[cut_off:], res): score[(t, p)] += 1\n",
    "for k, v in score.items():\n",
    "    print(f'{tab[k]:14}: {v:5} {float(100 * v / total):7.4f}%')\n",
    "correct = score[(0, 0)] + score[(1, 1)]\n",
    "print(f'TRUE NEG plus TRUE POS: {correct:5} {float(100 * correct / total):7.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(truth, pred):  # WS creation\n",
    "    total = truth.shape[0]\n",
    "    tab = {(1, 1): 'TRUE  POSITIVE', (1, 0): 'FALSE  NEGATIVE', \n",
    "           (0, 1): 'FALSE POSITIVE', (0, 0): 'TRUE   NEGATIVE'}\n",
    "    score = {(1, 1): 0, (0, 0): 0, (1, 0): 0, (0, 1): 0}\n",
    "    for t, p in zip(truth, pred): score[(t, p)] += 1\n",
    "    truth_table(tab, score)\n",
    "    correct = score[(0, 0)] + score[(1, 1)]\n",
    "    print(f'\\nTRUE NEG plus TRUE POS: {correct:5} ({float(100 * correct / total):7.4f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truth_table(name, values, width=55):  # WS\n",
    "    print(f'\\n{name[(1, 1)]:14}: {values[(1, 1)]:5}   |   {name[(1, 0)]:14}: {values[(1, 0)]:5}')\n",
    "    print(f'{\"\".join(\"_\"*width)}')\n",
    "    print(f'\\n{name[(0, 1)]:14}: {values[(0, 1)]:5}   |   {name[(0, 0)]:14}: {values[(0, 0)]:5}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y[:cut_off], clf.predict(X[:cut_off]))  # training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y[cut_off:], clf.predict(X[cut_off:]))  # validation sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOK AT SAMPLES OF ALL THINGS CALLED A COUNTRY IN A LARGER SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note: if too many vectors are taken, RAM will overflow, given that the word2vec dbase is also in RAM\n",
    "# the full 3000000 is too large to take at once\n",
    "#all_predictions = clf.predict(model.vectors[:1000000]) # 1e6 takes 30s to run\n",
    "batch_size = 100000  # takes 3 seconds for 100000\n",
    "batch_predictions = clf.predict(model.vectors[:batch_size, :]) # WS mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predictions.shape, sum(batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.index_to_key[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "# zip will go to the smallest of the length of batch_predictions or model.index_to_key\n",
    "for word, pred in zip(model.index_to_key, batch_predictions):  # WS index_to_key replaces index2word\n",
    "    if pred:\n",
    "        res.append(word)  # WS turned off break: see how many hits there are\n",
    "        #if len(res) == 150:\n",
    "        #    break\n",
    "random.sample(res, 20) # can see the country false-alarms mixed in with the true countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_to_idx = {country['name']: idx for idx, country in enumerate(countries)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_names = [k['name'] for k in countries]\n",
    "country_names.sort()\n",
    "#country_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_vecs = np.asarray([model[c['name']] for c in countries])  # get vector for each country\n",
    "country_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check to see what is similar to Canada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = np.dot(country_vecs, country_vecs[country_to_idx['Canada']])  # (184, 300) dot (300,) => (184,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_vecs[0].shape, dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in reversed(np.argsort(dists)[-10:]):\n",
    "    print(countries[idx]['name'], dists[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking countries for a specific term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_countries(term, topn=10, field='name'):\n",
    "    if not term in model:\n",
    "        return []\n",
    "    vec = model[term]\n",
    "    dists = np.dot(country_vecs, vec)\n",
    "    return [(countries[idx][field], float(dists[idx])) for idx in reversed(np.argsort(dists)[-topn:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_countries('cricket', field='name')  # field also can be 'cc' or 'cc3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize this on a world map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot some maps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#world['iso_a3'].map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_term(term):\n",
    "    d = {k.upper(): v for k, v in rank_countries(term, topn=0, field='cc3')}\n",
    "    print(len(d))\n",
    "    if len(d) > 0:  # WS added to handle empty results\n",
    "        world[term] = world['iso_a3'].map(d)  # WS this creates a new column for the dataframe 'world'\n",
    "        world[term] /= world[term].max()\n",
    "        world.dropna().plot(term, cmap='OrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('United_States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(world.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.dropna().plot('name', ) #cmap='OrRd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.dropna().plot('continent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.dropna().plot('gdp_md_est', cmap='prism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#world.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('coffee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(world['coffee'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('cricket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('China')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('vodka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('guns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('Panama_Canal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('accidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('murder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('poor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('G7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('wealthy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('paradise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_term('WWII')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

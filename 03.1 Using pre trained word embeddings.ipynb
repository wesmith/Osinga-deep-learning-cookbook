{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity using Word Embeddings\n",
    "\n",
    "In this notebook we're going to play around with pre build word embeddings and do some fun calcultations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06/17/23 NOTE: haven't run this in 4y 7m: the below comments were when run \n",
    "# on a macbook pro. Now on acer. \n",
    "\n",
    "# WS 02/13/19 adding the correct path for the env automatically by including the following path:\n",
    "# /home/smithw/.virtualenvs/osinga/lib/python3.6/site-packages\n",
    "# in the file \n",
    "# _virtualenv_path_extensions.pth in the env's /site-packages area; no need for the following line now\n",
    "#sys.path.insert(0,'/home/smithw/.virtualenvs/osinga/lib/python3.6/site-packages')\n",
    "#sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from keras.utils import get_file\n",
    "import gensim\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(10, 10)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import json\n",
    "from collections import Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by downloading a pretrained model from Google News. We're using `zcat` to unzip the file, so you need to make sure you have that installed or replace it by something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'GoogleNews-vectors-negative300.bin'\n",
    "# WS 06/17/23: this get_file() location is OBE: downloaded directly from\n",
    "# https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download\n",
    "\n",
    "#path = get_file(MODEL + '.gz', 'https://s3.amazonaws.com/dl4j-distribution/%s.gz' % MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.isdir('generated'):\n",
    "#    os.mkdir('generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '/home/smithw/Downloads/deep_learning' # WS: files not backed up here\n",
    "zipped   = os.path.join(data_loc, MODEL + '.gz')  # WS mod\n",
    "unzipped = os.path.join(data_loc, MODEL)  # WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped, unzipped"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# WS 06/17/23 this not unzipping, did it in terminal using 'gunzip'\n",
    "\n",
    "if not os.path.isfile(unzipped):\n",
    "    with open(unzipped, 'wb') as fout:\n",
    "        zcat = subprocess.Popen(['zcat'],\n",
    "                          #stdin=open(path),\n",
    "                          stdin=open(zipped), # WS mod\n",
    "                          stdout=fout)\n",
    "        zcat.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(unzipped, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WS 11/10/18 this model took about 10m to load on macbook pro\n",
    "# WS 06/17/23 took 35s to load on the acer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take this model for a spin by looking at what things are most similar to espresso. As expected, coffee like items show up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['espresso'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the famous equation, what is like woman if king is like man? We create a quick method to these calculations here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to listify inputs, WS comment\n",
    "a, b, c = 'hi', ['list'], 8\n",
    "a, b, c = map(lambda x:x if type(x) == list else [x], (a, b, c))\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_is_to_B_as_C_is_to(a, b, c, topn=1, score=False):  # WS added score output\n",
    "    a, b, c = map(lambda x:x if type(x) == list else [x], (a, b, c))  # WS listify inputs\n",
    "    res = model.most_similar(positive=b + c, negative=a, topn=topn)\n",
    "    if len(res):\n",
    "        if topn == 1:\n",
    "            if score: return res[0]\n",
    "            else:     return res[0][0]\n",
    "        if score: return res\n",
    "        else:     return [x[0] for x in res]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to('man', 'woman', 'king', topn=5, score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to('man', 'king', 'woman', topn=5, score=True) # identical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WS comment 06/17/23:\n",
    "# in embedding space, let x = (king - man) vector (ie, positive - negative inputs)\n",
    "# rewriting, this is king = man + x, or the x vector is pointing from man to king in embedding\n",
    "# then with input (woman + king) - man , rearranging it is woman + (king - man) \n",
    "# which is woman + x; if x points from man to king, presumably x also points approximately \n",
    "# from woman to queen if relationships are preserved; this is borne out by these results\n",
    "# also get identical results by swapping woman and king, as shown by the math above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_is_to_B_as_C_is_to('man', 'woman', 'boy', topn=5, score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.most_similar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this equation to acurately predict the capitals of countries by looking at what has the same relationship as Berlin has to Germany for selected countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in 'Italy', 'France', 'India', 'China', 'America', 'USA': # WS added last two: it fails\n",
    "    print('%s is the capital of %s' % \n",
    "          (A_is_to_B_as_C_is_to('Germany', 'Berlin', country, score=True), country))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do the same for important products for given companies. Here we seed the products equation with two products, the iPhone for Apple and Starbucks_coffee for Starbucks. Note that numbers are replaced by # in the embedding model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in 'Google', 'IBM', 'Boeing', 'Microsoft', 'Samsung':\n",
    "    products = A_is_to_B_as_C_is_to(\n",
    "        ['Starbucks', 'Apple'], \n",
    "        ['Starbucks_coffee', 'iPhone'], \n",
    "        company, topn=3)\n",
    "    print('%s -> %s' % \n",
    "          (company, ', '.join(products)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some clustering by picking three categories of items, drinks, countries and sports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beverages = ['espresso', 'beer', 'vodka', 'wine', 'cola', 'tea']\n",
    "countries = ['Italy', 'Germany', 'Russia', 'France', 'USA', 'India']\n",
    "sports    = ['soccer', 'handball', 'hockey', 'cycling', 'basketball', 'cricket']\n",
    "food      = ['hamburger', 'pizza', 'soup', 'steak', 'chicken']  # WS added\n",
    "vehicles  = ['airplane', 'locomotive', 'automobile', 'ship', 'submarine', 'rocket'] # WS added\n",
    "tools     = ['hammer', 'screwdriver', 'drill', 'ruler', 'pencil', 'level'] # WS added\n",
    "misc      = ['man', 'woman', 'king', 'queen']\n",
    "\n",
    "items = beverages + countries + sports + food + vehicles + tools + misc\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And looking up their vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors = [(item, model[item]) for item in items if item in model]\n",
    "len(item_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors[0][1].shape  # 300 dimensions in embedding space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use TSNE for clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors      = np.asarray([x[1] for x in item_vectors])\n",
    "lengths      = np.linalg.norm(vectors, axis=1)\n",
    "norm_vectors = (vectors.T / lengths).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vectors[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WS original: perplexity 10 (20 made it a worse clustering, 5 better), verbose=2\n",
    "tsne = TSNE(n_components=2, perplexity=8, verbose=1).fit_transform(norm_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And matplotlib to show the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tsne[:,0]\n",
    "y=tsne[:,1]\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "for item, x1, y1 in zip(item_vectors, x, y):\n",
    "    ax.annotate(item[0], (x1, y1), size=14)\n",
    "plt.grid() # WS\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in item_vectors:\n",
    "    print(k[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
